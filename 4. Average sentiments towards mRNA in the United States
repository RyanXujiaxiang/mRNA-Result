import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import sem, t
import plotly.express as px

df = pd.read_csv(".data")

us_data = df[df['Country'] == "United States"]
state_mapping = {"positive": 1, "neutral": 0, "negative": -1}
us_data["SentimentValue"] = us_data["Predicted_sentiment"].map(state_mapping)
us_data = us_data.dropna(subset=['State'])
us_data = us_data.dropna(subset=['SentimentValue'])

all_data_mean = df['Predicted_sentiment'].map(state_mapping).mean()

#state_avg_sentiment = us_data.groupby('State')['SentimentValue'].mean().reset_index()

state_to_code = {
    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO',
    'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',
    'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA',
    'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',
    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ',
    'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',
    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',
    'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',
    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY', 'Washington, D.C.': 'DC'
}

us_data['State'] = us_data['State'].map(state_to_code)

means = us_data.groupby('State')['SentimentValue'].mean()

standard_errors = us_data.groupby('State')['SentimentValue'].apply(sem)

confidence_intervals = standard_errors * t.ppf((1 + 0.95) / 2, us_data.groupby('State').size() - 1)

def map_size(count):
    min_size = 3   
    max_size = 8  
    range_count = us_data.groupby('State').size().max() - us_data.groupby('State').size().min()
    size = (count - us_data.groupby('State').size().min()) / range_count * (max_size - min_size) + min_size
    return size

state_counts = us_data['State'].value_counts()
sorted_means = means.sort_values(ascending=False)
overall_mean = us_data['SentimentValue'].mean()
overall_se = sem(us_data['SentimentValue'])
overall_ci = overall_se * t.ppf((1 + 0.95) / 2, len(us_data) - 1)

sorted_means['Overall'] = overall_mean
confidence_intervals['Overall'] = overall_ci

fig, ax = plt.subplots(figsize=(8, 18))

for state, mean in sorted_means.items():
    ci = confidence_intervals[state]
    size = map_size(state_counts[state]) if state != 'Overall' else 10
    ax.errorbar(mean, state, xerr=ci, fmt='s', markersize=size, color='black', ecolor='gray', elinewidth=2, capsize=5)

#ax.axvline(0, color='gray', linestyle='--', label='Zero Line') 
us_avg_line = ax.axvline(overall_mean, color='#ADD8E6', linestyle='--', label='Average Sentiment Score (United States)')
all_data_line = ax.axvline(all_data_mean, color='#D3D3D3', linestyle='--', label='Average Sentiment Score (World)')

ax.legend([us_avg_line, all_data_line], ['Average Sentiment Score (United States)', 'Average Sentiment Score (World)'], loc='upper right')
#ax.set_xlabel('Average Sentiment Score')
ax.set_title('Average Sentiment Score by State with 95% CI in the US')

mean_text_x_position = ax.get_xlim()[1] + 0.01
n_text_x_position = mean_text_x_position + 0.15

for state, mean_val in means.items():
    ci_val = confidence_intervals[state]
    count_val = state_counts[state]
    
    text_content = f"{mean_val:.3f} [{mean_val - ci_val:.3f}, {mean_val + ci_val:.3f}]"
    ax.text(mean_text_x_position, state, text_content, verticalalignment='center', ha='left')
    
    ax.text(n_text_x_position, state, f"{count_val}", verticalalignment='center', ha='left')

text_content = f"{overall_mean:.3f} ({overall_mean - overall_ci:.3f}, {overall_mean + overall_ci:.3f})"
ax.text(mean_text_x_position, "Overall", text_content, verticalalignment='center', ha='left')
ax.text(n_text_x_position, "Overall", f"{len(us_data)}", verticalalignment='center', ha='left')

y_max = sorted_means.size

title_y_position = y_max - 52.8

ax.text(mean_text_x_position + 0.075, title_y_position, "Mean[95% CI]", verticalalignment='center', ha='center', fontweight='bold')
ax.text(n_text_x_position+0.015, title_y_position, "N", verticalalignment='center', ha='center', fontweight='bold')

for spine in ax.spines.values():
    spine.set_visible(False)

ax.yaxis.grid(True, color='white', linewidth=1)
ax.xaxis.grid(True, color='white', linewidth=1)

ax.yaxis.set_ticks_position('none')

plt.gca().invert_yaxis()
plt.show()
